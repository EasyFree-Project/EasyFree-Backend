{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4582d230e25b8217e666f0f9ff9e4572247d830a78f80b8cc5849d556084ed3c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 구축한 학습 데이터로 학습 완료\n",
    "## 멀티 클래스 분류 방법 확인 완료 !!!!!!!!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "메모리 에러  \n",
    "CUDA error: device-side assert triggered"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#CV\n",
    "import cv2\n",
    "\n",
    "################# DETR FUCNTIONS FOR LOSS######################## \n",
    "import sys\n",
    "sys.path.extend(['./tmp/packages/detr/'])\n",
    "\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "#################################################################\n",
    "\n",
    "#Albumenatations\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "#Glob\n",
    "from glob import glob"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        \n",
    "    @property\n",
    "    def avg(self):\n",
    "        return (self.sum / self.count) if self.count>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "seed = 42\n",
    "null_class_coef = 0.5\n",
    "num_classes = 17 # class 수 변경\n",
    "num_queries = 100\n",
    "BATCH_SIZE = 8\n",
    "LR = 5e-5\n",
    "lr_dict = {'backbone':0.1,'transformer':1,'embed':1,'final': 5}\n",
    "EPOCHS = 2\n",
    "max_norm = 0\n",
    "model_name = 'detr_resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "marking = pd.read_csv('/home/lab10/JJC/EasyFree/IMAGE/coco_train.csv').reset_index()\n",
    "marking.columns = ['bg_name','category','x','y','w','h','source']\n",
    "marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels 값은 1부터 Length까지\n",
    "i=0\n",
    "category_to_label = {}\n",
    "for c in marking['category'].unique():\n",
    "    i+=1\n",
    "    category_to_label[c] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = list(category_to_label.keys())\n",
    "# CLASSES.append('N/A')\n",
    "# CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('/home/lab10/JJC/EasyFree/COLLECT_DATA/emart_category.csv')\n",
    "CATEGORY_LIST = []\n",
    "for c in CLASSES:\n",
    "    CATEGORY_LIST.append(temp[temp['category_number'] == c]['category_name'].values[0])\n",
    "CATEGORY_LIST.append('N/A')\n",
    "CATEGORY_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_LIST = ['chili powder','fruit','onion','potato','sweet potato','Chili pepper', 'Tofu','Vegetables','Cold Fruit','Paprika','garlic','Sesame','Simple Fruit','Pimang','bean sprouts','Pa','Lettuce','N/A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    image_id  width  height   source      x      y      w      h\n",
       "0  b6ab77fd7   1024    1024  usask_1  834.0  222.0   56.0   36.0\n",
       "1  b6ab77fd7   1024    1024  usask_1  226.0  548.0  130.0   58.0\n",
       "2  b6ab77fd7   1024    1024  usask_1  377.0  504.0   74.0  160.0\n",
       "3  b6ab77fd7   1024    1024  usask_1  834.0   95.0  109.0  107.0\n",
       "4  b6ab77fd7   1024    1024  usask_1   26.0  144.0  124.0  117.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>width</th>\n      <th>height</th>\n      <th>source</th>\n      <th>x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b6ab77fd7</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>usask_1</td>\n      <td>834.0</td>\n      <td>222.0</td>\n      <td>56.0</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b6ab77fd7</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>usask_1</td>\n      <td>226.0</td>\n      <td>548.0</td>\n      <td>130.0</td>\n      <td>58.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b6ab77fd7</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>usask_1</td>\n      <td>377.0</td>\n      <td>504.0</td>\n      <td>74.0</td>\n      <td>160.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b6ab77fd7</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>usask_1</td>\n      <td>834.0</td>\n      <td>95.0</td>\n      <td>109.0</td>\n      <td>107.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b6ab77fd7</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>usask_1</td>\n      <td>26.0</td>\n      <td>144.0</td>\n      <td>124.0</td>\n      <td>117.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# 카테고리 값 변경\n",
    "marking['category'] = marking['category'].apply(lambda i : category_to_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일명과 source(?), 박스 정보를 가져옴\n",
    "\n",
    "image_data = marking.groupby('bg_name')\n",
    "images = list(map(lambda x: x.split('.')[0], os.listdir('/home/lab10/JJC/EasyFree/IMAGE/Train_Image')))\n",
    "\n",
    "def get_data(img_id):\n",
    "    if img_id not in image_data.groups:\n",
    "        return dict(image_id=img_id, source='', boxes=list())\n",
    "    \n",
    "    data  = image_data.get_group(img_id)\n",
    "    source = np.unique(data.source.values)\n",
    "    assert len(source)==1, 'corrupted data: %s image_id has many sources: %s' %(img_id,source)\n",
    "    source=source[0]\n",
    "    boxes = data[['x','y','w','h']].values\n",
    "    labels = data['category'].values\n",
    "    return dict(image_id = img_id, boxes = boxes, labels = labels, source=source)\n",
    "\n",
    "image_list = [get_data(img_id) for img_id in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'total number of images: {len(image_list)}, images with bboxes: {len(image_data)}')\n",
    "null_images=[x['image_id'] for x in image_list if len(x['boxes'])==0]\n",
    "len(null_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fold_index(lst,n_folds):\n",
    "    lens = [len(x['boxes']) for x in lst]\n",
    "    lens_unique = np.unique(lens)\n",
    "    i = np.random.randint(n_folds)\n",
    "    fold_indexes = [[] for _ in range(n_folds)]\n",
    "    idx = []\n",
    "    \n",
    "    for _l in lens_unique:\n",
    "        idx.extend(np.nonzero(lens==_l)[0].tolist())\n",
    "        if len(idx)<n_folds: continue\n",
    "        random.shuffle(idx)\n",
    "        while len(idx)>= n_folds:\n",
    "            fold_indexes[i].append(lst[idx.pop()]['image_id'])\n",
    "            i = (i+1) % n_folds\n",
    "    while len(idx):\n",
    "        fold_indexes[i].append(lst[idx.pop()]['image_id'])\n",
    "        i = (i+1) % n_folds\n",
    "    \n",
    "    return fold_indexes\n",
    "    \n",
    "sources = np.unique([x['source'] for x in image_list])\n",
    "splitted_image_list = {s:sorted([x for x in image_list if x['source']==s],key=lambda x: len(x['boxes'])) \n",
    "                       for s in sources}\n",
    "splitted_image_list = {k: add_fold_index(v,n_folds=n_folds) for k,v in splitted_image_list.items()}\n",
    "\n",
    "fold_indexes = [[] for _ in range(n_folds)]\n",
    "for k,v in splitted_image_list.items():\n",
    "    for i in range(n_folds):\n",
    "        fold_indexes[i].extend(v[i])  \n",
    "    \n",
    "print([len(v) for v in fold_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True로 할 시 박스 정보 없는 데이터 보여줌\n",
    "if False:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i,img in enumerate(null_images):\n",
    "        if i==50:break\n",
    "        plt.subplot(7,7,i+1)\n",
    "        plt.imshow(plt.imread(f'/home/lab10/JJC/EasyFree/IMAGE/Train_Image/{img}.jpg'))\n",
    "        plt.axis('off')\n",
    "        plt.axis('tight')\n",
    "        plt.axis('equal')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.OneOf(\n",
    "            [\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, val_shift_limit=0.2, p=0.9),      \n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.9)\n",
    "            ],\n",
    "            p=0.9),         \n",
    "            #A.ToGray(p=0.01),         \n",
    "            A.HorizontalFlip(p=0.5),         \n",
    "            A.VerticalFlip(p=0.5),         \n",
    "            A.Resize(height=512, width=512, p=1),      \n",
    "            A.Normalize(max_pixel_value=1),\n",
    "            #A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], \n",
    "        p=1.0,         \n",
    "        bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "        )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "                      A.Resize(height=512, width=512, p=1.0),\n",
    "                      A.Normalize(max_pixel_value=1),\n",
    "                      ToTensorV2(p=1.0),\n",
    "                      ], \n",
    "                      p=1.0, \n",
    "                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = '/home/lab10/JJC/EasyFree/IMAGE/Train_Image'\n",
    "class WheatDataset(Dataset):\n",
    "    def __init__(self,image_list,transforms=None):\n",
    "        self.images = image_list\n",
    "        self.transforms = transforms\n",
    "        self.img_ids = {x['image_id']:i for i,x in enumerate(image_list)}\n",
    "        \n",
    "    def get_indices(self,img_ids):\n",
    "        return [self.img_ids[x] for x in img_ids]\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        record = self.images[index]\n",
    "        image_id = record['image_id']\n",
    "\n",
    "        image = cv2.imread(f'{DIR_TRAIN}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        # DETR takes in data in coco format \n",
    "        boxes = record['boxes'] \n",
    "        \n",
    "        ################################### Box 라벨링 하는 곳 - 값 받아서 처리 - image별로 box 에 따라 라벨이 정해짐, 나중에 변경\n",
    "        # image_list에 labels 부분을 만들어서 사용\n",
    "        labels = np.asarray(record['labels'], dtype=np.int32) if len(boxes) else np.zeros(len(boxes), dtype=np.int32)\n",
    "        # labels = np.zeros(len(boxes), dtype=np.int32)\n",
    "        # labels[len(labels)//3:2*len(labels)//3] = 1\n",
    "        # labels[2*len(labels)//3:] = 2\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': boxes,\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image  = sample['image']\n",
    "            boxes  = sample['bboxes']\n",
    "            labels = sample['labels']\n",
    "\n",
    "        _,h,w = image.shape\n",
    "        boxes = A.augmentations.bbox_utils.normalize_bboxes(sample['bboxes'],rows=h,cols=w)\n",
    "        ## detr uses center_x,center_y,width,height !!\n",
    "        if len(boxes)>0:\n",
    "            boxes = np.array(boxes)\n",
    "            boxes[:,2:] /= 2\n",
    "            boxes[:,:2] += boxes[:,2:]\n",
    "        else:\n",
    "            boxes = np.zeros((0,4))\n",
    "    \n",
    "        target = {}\n",
    "        target['boxes'] = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels,dtype=torch.long)\n",
    "        target['image'] = torch.tensor([index])\n",
    "        \n",
    "        return image, target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WheatDataset(image_list,get_train_transforms())\n",
    "valid_ds = WheatDataset(image_list,get_valid_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(image,target,image_id=None):\n",
    "    np_image = image.cpu().numpy().transpose((1,2,0))\n",
    "    # unnormalize the image\n",
    "    np_image = np_image * np.array([0.229, 0.224, 0.225])+np.array([0.485, 0.456, 0.406])\n",
    "    # np_image = (np_image*255).astype(np.uint8)\n",
    "    target = {k: v.cpu().numpy() for k, v in target.items()}\n",
    "    \n",
    "    # target : 학습용 박스 정보\n",
    "    # print(target)\n",
    "    \n",
    "    boxes = target['boxes']\n",
    "    h,w,_ = np_image.shape\n",
    "    boxes = [np.array(box).astype(np.int32) for box in A.augmentations.bbox_utils.denormalize_bboxes(boxes,h,w)]\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        cv2.rectangle(np_image,\n",
    "                  (box[0]-box[2], box[1]-box[3]),\n",
    "                  (box[2]+box[0], box[3]+box[1]),\n",
    "                  # 라벨별 박스 색깔 변경\n",
    "                  (220, 0, 0) if target['labels'][i] == 0 else (0,220,0) if target['labels'][i] == 1 else (0,0,220) , 1)\n",
    "        \n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(np_image)\n",
    "    ax.set_title(image_id)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_example(*train_ds[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DETRModel(num_classes,model_name=model_name):\n",
    "    model = torch.hub.load('facebookresearch/detr', model_name, pretrained=False, num_classes=num_classes)\n",
    "    def parameter_groups(self):\n",
    "        return { 'backbone': [p for n,p in self.named_parameters()\n",
    "                              if ('backbone' in n) and p.requires_grad],\n",
    "                 'transformer': [p for n,p in self.named_parameters() \n",
    "                                 if (('transformer' in n) or ('input_proj' in n)) and p.requires_grad],\n",
    "                 'embed': [p for n,p in self.named_parameters()\n",
    "                                 if (('class_embed' in n) or ('bbox_embed' in n) or ('query_embed' in n)) \n",
    "                           and p.requires_grad]}\n",
    "    setattr(type(model),'parameter_groups',parameter_groups)\n",
    "    return model\n",
    "\n",
    "class DETRModel(nn.Module):\n",
    "    def __init__(self,num_classes=1):\n",
    "        super(DETRModel,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.model = torch.hub.load('facebookresearch/detr', model_name, pretrained=True)\n",
    "        \n",
    "        self.out = nn.Linear(in_features=self.model.class_embed.out_features,out_features=num_classes+1)\n",
    "        \n",
    "    def forward(self,images):\n",
    "        d = self.model(images)\n",
    "        d['pred_logits'] = self.out(d['pred_logits'])\n",
    "        return d\n",
    "    \n",
    "    def parameter_groups(self):\n",
    "        return { \n",
    "            'backbone': [p for n,p in self.model.named_parameters()\n",
    "                              if ('backbone' in n) and p.requires_grad],\n",
    "            'transformer': [p for n,p in self.model.named_parameters() \n",
    "                                 if (('transformer' in n) or ('input_proj' in n)) and p.requires_grad],\n",
    "            'embed': [p for n,p in self.model.named_parameters()\n",
    "                                 if (('class_embed' in n) or ('bbox_embed' in n) or ('query_embed' in n)) \n",
    "                           and p.requires_grad],\n",
    "            'final': self.out.parameters()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DETRModel(num_classes = num_classes)\n",
    "model.parameter_groups().keys()\n",
    "#type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "code taken from github repo detr , 'code present in engine.py'\n",
    "'''\n",
    "\n",
    "matcher = HungarianMatcher(cost_giou=2,cost_class=1,cost_bbox=5)\n",
    "\n",
    "weight_dict = {'loss_ce': 1, 'loss_bbox': 5 , 'loss_giou': 2}\n",
    "\n",
    "losses = ['labels', 'boxes', 'cardinality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 Torch DataLoader 형식으로 변환\n",
    "\n",
    "def get_fold(fold):\n",
    "    \n",
    "    train_indexes = train_ds.get_indices([x for i,f in enumerate(fold_indexes) if i!=fold for x in f])\n",
    "    valid_indexes = valid_ds.get_indices(fold_indexes[fold])\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "        torch.utils.data.Subset(train_ds,train_indexes),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    valid_data_loader = DataLoader(\n",
    "        torch.utils.data.Subset(valid_ds,valid_indexes),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_data_loader,valid_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,valid_loader = get_fold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = iter(valid_loader)\n",
    "batch  = next(valid_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.box_ops  as box_ops\n",
    "\n",
    "def challenge_metric(outputs,targets):\n",
    "    logits = outputs['pred_logits']\n",
    "    boxes  = outputs['pred_boxes']\n",
    "    return sum(avg_precision(logit[:,0]-logit[:,1],box,target['boxes'])\n",
    "            for logit,box,target in zip(logits,boxes,targets))/len(logits)\n",
    "\n",
    "    return {target['image_id']:avg_precision(logit[:,0]-logit[:,1],box,target['boxes'])\n",
    "            for logit,box,target in zip(logits,boxes,targets)}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def avg_precision(logit,pboxes,tboxes,reduce=True):\n",
    "    idx = logit.gt(0)\n",
    "    if sum(idx)==0 and len(tboxes)==0: \n",
    "        return 1 if reduce else [1]*6\n",
    "    if sum(idx)>0 and len(tboxes)==0: \n",
    "        return 0 if reduce else [0]*6\n",
    "    \n",
    "    pboxes = pboxes[idx]\n",
    "    logit = logit[idx]\n",
    "    \n",
    "    idx = logit.argsort(descending=True)\n",
    "    pboxes=box_ops.box_cxcywh_to_xyxy(pboxes.detach()[idx])\n",
    "    tboxes=box_ops.box_cxcywh_to_xyxy(tboxes)\n",
    "    \n",
    "    iou = box_ops.box_iou(pboxes,tboxes)[0].cpu().numpy()\n",
    "    prec = [precision(iou,th) for th in [0.5,0.55,0.6,0.65,0.7,0.75]]\n",
    "    if reduce:\n",
    "        return sum(prec)/6\n",
    "    return prec\n",
    "    \n",
    "\n",
    "def precision(iou,th):\n",
    "    #if iou.shape==(0,0): return 1\n",
    "\n",
    "    #if min(*iou.shape)==0: return 0\n",
    "    tp = 0\n",
    "    iou = iou.copy()\n",
    "    num_pred,num_gt = iou.shape\n",
    "    for i in range(num_pred):\n",
    "        _iou = iou[i]\n",
    "        n_hits = (_iou>th).sum()\n",
    "        if n_hits>0:\n",
    "            tp += 1\n",
    "            j = np.argmax(_iou)\n",
    "            iou[:,j] = 0\n",
    "    return tp/(num_pred+num_gt-tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_box(n,scale=1):\n",
    "    par = torch.randn((n,4)).mul(scale).sigmoid() \n",
    "    max_hw = 2*torch.min(par[:,:2],1-par[:,:2])\n",
    "    par[:,2:] = par[:,2:].min(max_hw)\n",
    "    return par\n",
    "\n",
    "pboxes = gen_box(50)\n",
    "logit = torch.randn(50)\n",
    "tboxes = gen_box(3)\n",
    "\n",
    "avg_precision(logit,pboxes,tboxes)\n",
    "#iou.gt(0.5),iou,pboxes,tboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_fn(data_loader,model,criterion,optimizer,device,scheduler,epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    tk0 = tqdm(data_loader, total=len(data_loader),leave=False)\n",
    "    log = None\n",
    "    \n",
    "    for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "        \n",
    "        batch_size = len(images)\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        output = model(images)\n",
    "        \n",
    "        loss_dict = criterion(output, targets)\n",
    "        \n",
    "        if log is None:\n",
    "            log = {k:AverageMeter() for k in loss_dict}\n",
    "            log['total_loss'] = AverageMeter()\n",
    "            log['avg_prec'] = AverageMeter()\n",
    "            \n",
    "        weight_dict = criterion.weight_dict\n",
    "        \n",
    "        total_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss.backward()\n",
    "        \n",
    "        if max_norm > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        log['total_loss'].update(total_loss.item(),batch_size)\n",
    "        \n",
    "        for k,v in loss_dict.items():\n",
    "            log[k].update(v.item(),batch_size)\n",
    "            \n",
    "        log['avg_prec'].update(challenge_metric(output,targets),batch_size)\n",
    "            \n",
    "        tk0.set_postfix({k:v.avg for k,v in log.items()}) \n",
    "        \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def eval_fn(data_loader, model,criterion, device):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    log = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        tk0 = tqdm(data_loader, total=len(data_loader),leave=False)\n",
    "        for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "            \n",
    "            batch_size = len(images)\n",
    "            \n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            output = model(images)\n",
    "        \n",
    "            loss_dict = criterion(output, targets)\n",
    "            weight_dict = criterion.weight_dict\n",
    "        \n",
    "            if log is None:\n",
    "                log = {k:AverageMeter() for k in loss_dict}\n",
    "                log['total_loss'] = AverageMeter()\n",
    "                log['avg_prec'] = AverageMeter()\n",
    "            \n",
    "            for k,v in loss_dict.items():\n",
    "                log[k].update(v.item(),batch_size)\n",
    "        \n",
    "            total_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "            log['total_loss'].update(total_loss.item(),batch_size)\n",
    "            log['avg_prec'].update(challenge_metric(output,targets),batch_size)\n",
    "            \n",
    "            tk0.set_postfix({k:v.avg for k,v in log.items()}) \n",
    "    \n",
    "    return log #['total_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 로그 처리, Run 함수\n",
    "\n",
    "import json\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self,filename,format='csv'):\n",
    "        self.filename = filename + '.' + format\n",
    "        self._log = []\n",
    "        self.format = format\n",
    "    def save(self,log,epoch=None):\n",
    "        log['epoch'] = epoch+1\n",
    "        self._log.append(log)\n",
    "        if self.format == 'json':\n",
    "            with open(self.filename,'w') as f:\n",
    "                json.dump(self._log,f)\n",
    "        else:\n",
    "            pd.DataFrame(self._log).to_csv(self.filename,index=False)\n",
    "            \n",
    "            \n",
    "def run(fold,epochs=EPOCHS):\n",
    "    \n",
    "    train_data_loader,valid_data_loader = get_fold(fold)\n",
    "    \n",
    "    logger = Logger(f'log_{fold}')\n",
    "    device = torch.device('cuda')\n",
    "    model = DETRModel(num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "    criterion = SetCriterion(num_classes, \n",
    "                             matcher, weight_dict, \n",
    "                             eos_coef = null_class_coef, \n",
    "                             losses=losses)\n",
    "    \n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "\n",
    "    optimizer = torch.optim.AdamW([{\n",
    "        'params': v,\n",
    "        'lr': lr_dict.get(k,1)*LR\n",
    "    } for k,v in model.parameter_groups().items()], weight_decay=1e-4)\n",
    "    \n",
    "    best_precision = 0\n",
    "    header_printed = False\n",
    "    for epoch in range(epochs):\n",
    "        train_log = train_fn(train_data_loader, model,criterion, optimizer,device,scheduler=None,epoch=epoch)\n",
    "        valid_log = eval_fn(valid_data_loader, model,criterion, device)\n",
    "    \n",
    "        log = {k:v.avg for k,v in train_log.items()}\n",
    "        log.update({'V/'+k:v.avg for k,v in valid_log.items()})\n",
    "        logger.save(log,epoch)\n",
    "        keys = sorted(log.keys())\n",
    "        \n",
    "        if not header_printed:\n",
    "            print(' '.join(map(lambda k: f'{k[:8]:8}',keys)))\n",
    "            header_printed = True\n",
    "        print(' '.join(map(lambda k: f'{log[k]:8.3f}'[:8],keys)))\n",
    "        \n",
    "        if log['V/avg_prec'] > best_precision:\n",
    "            best_precision = log['V/avg_prec']\n",
    "            print('Best model found at epoch {}'.format(epoch+1))\n",
    "            torch.save(model.state_dict(), f'detr_best_{fold}.pth')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=0,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(images,outputs,targets):\n",
    "    _,h,w = images[0].shape\n",
    "    \n",
    "    boxes = targets[0]['boxes'].cpu().numpy() #.astype(np.int32)\n",
    "    boxes = [np.array(box).astype(np.int32) for box in A.augmentations.bbox_utils.denormalize_bboxes(boxes,h,w)]\n",
    "    np_image = images[0].permute(1,2,0).cpu().numpy()\n",
    "    np_image = np_image*np.array([0.229, 0.224, 0.225])+np.array([0.485, 0.456, 0.406])\n",
    "    \n",
    "    #outputs = [{k: v.cpu() for k, v in output.items()}]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    labels = targets[0]['labels']\n",
    "    for box, label in zip(boxes, labels):\n",
    "        x, y = (box[0]-box[2], box[1]-box[3])\n",
    "        cv2.rectangle(np_image,\n",
    "                  (box[0]-box[2], box[1]-box[3]),\n",
    "                  (box[2]+box[0], box[3]+box[1]),\n",
    "                  (220, 0, 0), 2)\n",
    "        CATEGORY_NAME = str(CATEGORY_LIST[label-1])\n",
    "        cv2.putText(np_image, CATEGORY_NAME, (x, y-1), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (220,0,0), 2)\n",
    "    \n",
    "    oboxes = outputs['pred_boxes'][0].detach().cpu().numpy()\n",
    "    oboxes = [np.array(box).astype(np.int32) for box in A.augmentations.bbox_utils.denormalize_bboxes(oboxes,h,w)]\n",
    "    # prob   = outputs['pred_logits'][0].softmax(1).detach().cpu().numpy()[:,0] # 2진 분류\n",
    "    prob   = outputs['pred_logits'].softmax(-1).detach().cpu().numpy()[0, :, :-1] # 멀티클래스 분류\n",
    "    for box,p in zip(oboxes,prob):\n",
    "        cl = p.argmax()\n",
    "        if p[cl] > 0.2:\n",
    "            # color = (0,0,220) if p>0.5 else (0,220,0)\n",
    "            color = (0,0,220)\n",
    "            x, y = box[0]-box[2], box[1]-box[3]\n",
    "            cv2.rectangle(np_image,\n",
    "                        (x, y),\n",
    "                        (box[2]+box[0], box[3]+box[1]),\n",
    "                        color, 1)\n",
    "            CATEGORY_NAME = CATEGORY_LIST[cl]\n",
    "            text = f'{CATEGORY_NAME}: {p[cl]:0.2f}'\n",
    "            cv2.putText(np_image, text, (x, y-1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(np_image)\n",
    "    #return images,outputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DETRModel(num_classes=num_classes)#,num_queries=num_queries\n",
    "model.load_state_dict(torch.load(\"./detr_best_0.pth\"))\n",
    "model.to(torch.device('cuda'))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,valid_loader = get_fold(0)\n",
    "valid_iter = iter(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,targets,image_id = next(valid_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_images = [img.to(torch.device('cuda')) for img in images]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 예측\n",
    "    outputs = model(dev_images)\n",
    "outputs = {k: v.cpu() for k, v in outputs.items()}\n",
    "show_predictions(images,outputs,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}